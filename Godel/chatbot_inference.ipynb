{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -r /kaggle/input/lynhatnam44/NLP/requirement.txt --upgrade","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-07T04:11:25.014859Z","iopub.execute_input":"2023-07-07T04:11:25.016063Z","iopub.status.idle":"2023-07-07T04:15:00.549544Z","shell.execute_reply.started":"2023-07-07T04:11:25.015986Z","shell.execute_reply":"2023-07-07T04:15:00.547632Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (4.30.1)\nCollecting transformers (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1))\n  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (2.1.0)\nCollecting datasets (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2))\n  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 3)) (3.2.4)\nCollecting nltk (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 3))\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 4)) (1.0.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 5)) (1.2.2)\nCollecting scikit-learn (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 5))\n  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sacrebleu (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 6))\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rouge_score (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 7))\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 8)) (0.12.0)\nCollecting accelerate (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 8))\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (2.0.0+cpu)\nCollecting torch (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 10)) (3.8.0)\nCollecting h5py (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 10))\n  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting datasketch (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 11))\n  Downloading datasketch-1.5.9-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting revChatGPT (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading revChatGPT-6.7.6-py3-none-any.whl (33 kB)\nCollecting evaluate (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 13))\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting openai (from -r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 14))\n  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (4.64.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (9.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (3.8.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 3)) (8.1.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 3)) (1.2.0)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 5)) (1.10.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 5)) (3.1.0)\nCollecting portalocker (from sacrebleu->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 6))\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 6)) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 6)) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 6)) (4.9.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 7)) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 7)) (1.16.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 8)) (5.9.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting triton==2.0.0 (from torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (59.8.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (0.40.0)\nCollecting cmake (from triton==2.0.0->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lit (from triton==2.0.0->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9))\n  Downloading lit-16.0.6.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting OpenAIAuth>=2.0.0 (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading OpenAIAuth-2.0.0-py3-none-any.whl (5.1 kB)\nCollecting httpx[socks] (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting async-tio (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading async_tio-1.3.2-py3-none-any.whl (8.2 kB)\nRequirement already satisfied: prompt-toolkit in /opt/conda/lib/python3.10/site-packages (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (3.0.38)\nCollecting tiktoken>=0.3.0 (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting curl-cffi (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading curl_cffi-0.5.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (13.3.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 13)) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (2023.5.7)\nRequirement already satisfied: cffi>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from curl-cffi->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (1.15.1)\nCollecting httpcore<0.18.0,>=0.15.0 (from httpx[socks]->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx[socks]->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (1.3.0)\nCollecting socksio==1.* (from httpx[socks]->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12))\n  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (2.1.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 2)) (2023.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (0.2.6)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 1)) (1.7.1)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (2.15.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 9)) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12.0->curl-cffi->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (2.21)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[socks]->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (0.14.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[socks]->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (3.6.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->revChatGPT->-r /kaggle/input/lynhatnam44/NLP/requirement.txt (line 12)) (0.1.2)\nBuilding wheels for collected packages: rouge_score, lit\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=9d0d171a5bcee478cf282aaac020d38019e0b7ee92748f967366d58bce6d1c49\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93582 sha256=edf73616eb1fb13b8cc6ea90aaf0eab1a245cd85d0ec4b9e9ec3ec18e032d670\n  Stored in directory: /root/.cache/pip/wheels/14/f9/07/bb2308587bc2f57158f905a2325f6a89a2befa7437b2d7e137\nSuccessfully built rouge_score lit\nInstalling collected packages: lit, cmake, socksio, portalocker, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nltk, h5py, tiktoken, scikit-learn, sacrebleu, rouge_score, OpenAIAuth, nvidia-cusolver-cu11, nvidia-cudnn-cu11, httpcore, datasketch, curl-cffi, transformers, openai, httpx, async-tio, datasets, revChatGPT, evaluate, triton, torch, accelerate\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.8.0\n    Uninstalling h5py-3.8.0:\n      Successfully uninstalled h5py-3.8.0\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.1\n    Uninstalling transformers-4.30.1:\n      Successfully uninstalled transformers-4.30.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0+cpu\n    Uninstalling torch-2.0.0+cpu:\n      Successfully uninstalled torch-2.0.0+cpu\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\ntorchaudio 2.0.1+cpu requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\ntorchtext 0.15.1+cpu requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\ntorchvision 0.15.1+cpu requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed OpenAIAuth-2.0.0 accelerate-0.20.3 async-tio-1.3.2 cmake-3.26.4 curl-cffi-0.5.7 datasets-2.13.1 datasketch-1.5.9 evaluate-0.4.0 h5py-3.9.0 httpcore-0.17.3 httpx-0.24.1 lit-16.0.6 nltk-3.8.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-0.27.8 portalocker-2.7.0 revChatGPT-6.7.6 rouge_score-0.1.2 sacrebleu-2.3.1 scikit-learn-1.3.0 socksio-1.0.0 tiktoken-0.4.0 torch-2.0.1 transformers-4.30.2 triton-2.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/input/lynhatnam44/NLP/Godel/inference.py --num 3 \\\n                                                         --thres 0.8\\\n                                                         --type minhashLSH \\\n                                                         --model_path /kaggle/input/godel-chatbot-model/official_model/model-v1.0.0\\\n                                                         --strategy combine\\\n                                                         --document_file /kaggle/input/lynhatnam44/NLP/data/document_context_data","metadata":{"execution":{"iopub.status.busy":"2023-07-07T04:21:24.436801Z","iopub.execute_input":"2023-07-07T04:21:24.437214Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nMedi: Hello, I am Medi, an online healcare chatbot. How can I help you today?\nYou: ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}